{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# import gymnasium as gym\n",
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "import pygame\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "class MazeGameEnv(gym.Env):\n",
    "    \"\"\"\n",
    "        Maze Game Environment\n",
    "\n",
    "        The maze is represented as a 2D numpy array where:\n",
    "            'S' is the start position\n",
    "            'G' is the goal position\n",
    "            'X' is a wall\n",
    "            ' ' is an empty space\n",
    "\n",
    "        The agent can move in 4 directions:\n",
    "            0: Up\n",
    "            1: Down\n",
    "            2: Left\n",
    "            3: Right\n",
    "\n",
    "        The agent receives a reward of 1.0 when it reaches the goal position and 0.0 otherwise.\n",
    "\n",
    "        :param maze: 2D numpy array representing the maze\n",
    "        :type maze: np.ndarray\n",
    "\n",
    "        :param cell_size: Size of each cell in the maze\n",
    "        :type cell_size: int\n",
    "\n",
    "        :param screen: Pygame screen object\n",
    "        :type screen: pygame.Surface\n",
    "\n",
    "        :param start_pos: Start position of the agent\n",
    "        :type start_pos: Tuple[int, int]\n",
    "\n",
    "        :param goal_pos: Goal position of the agent\n",
    "        :type goal_pos: Tuple[int, int]\n",
    "\n",
    "        :param current_pos: Current position of the agent\n",
    "        :type current_pos: Tuple[int, int]\n",
    "\n",
    "        :param num_rows: Number of rows in the maze\n",
    "        :type num_rows: int\n",
    "\n",
    "        :param num_cols: Number of columns in the maze\n",
    "        :type num_cols: int\n",
    "\n",
    "        :param action_space: Action space of the environment\n",
    "        :type action_space: gym.spaces.Discrete\n",
    "\n",
    "        :param observation_space: Observation space of the environment\n",
    "        :type observation_space: gym.spaces.Tuple\n",
    "\n",
    "        :param screen: Pygame screen object\n",
    "        :type screen: pygame.Surface\n",
    "\n",
    "        :param cell_size: Size of each cell in the maze\n",
    "        :type cell_size: int\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, maze):\n",
    "        super().__init__()\n",
    "        self.maze = np.array(maze) # 2d array\n",
    "        self.start_pos = (np.where(self.maze == 'S')[0][0], np.where(self.maze == 'S')[1][0])\n",
    "        self.goal_pos = (np.where(self.maze == 'G')[0][0], np.where(self.maze == 'G')[1][0])\n",
    "        self.current_pos = self.start_pos\n",
    "        self.num_rows, self.num_cols = self.maze.shape\n",
    "        self.X_pos = self.locate_X()\n",
    "        self.move_count = 0\n",
    "\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "        self.observation_space = gym.spaces.Discrete(self.num_rows * self.num_cols)\n",
    "\n",
    "        # print(self.X_pos)\n",
    "\n",
    "        pygame.init()\n",
    "        self.cell_size = 125\n",
    "        self.screen = pygame.display.set_mode((self.num_cols * self.cell_size, self.num_rows * self.cell_size))\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        \"\"\"\n",
    "            Reset agent position to start position\n",
    "        \"\"\"\n",
    "        super().reset(seed=seed)\n",
    "        self._init_temp_walls()\n",
    "        self.current_pos = self.start_pos\n",
    "        state_index = self._pos_to_index(self.current_pos)\n",
    "        self.move_count = 0\n",
    "        return state_index, {}\n",
    "\n",
    "    def locate_X(self):\n",
    "        temp_X_pos = []\n",
    "        for row in range(self.num_rows):\n",
    "            for col in range(self.num_cols):\n",
    "                if self.maze[row, col].startswith('X'):\n",
    "                    temp_X_pos.append((row, col, self.maze[row, col]))\n",
    "        return temp_X_pos\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "            Updates agentâ€™s position according to the action taken and provide reward\n",
    "        \"\"\"\n",
    "        self._update_Xes()        \n",
    "        moved = False\n",
    "\n",
    "        new_pos = np.array(self.current_pos)\n",
    "        direction = self._translate_action(action)\n",
    "        new_pos = new_pos[0] + direction[0], new_pos[1] + direction[1]\n",
    "\n",
    "        if self._is_valid_position(new_pos):\n",
    "            self.current_pos = new_pos\n",
    "            moved = True\n",
    "\n",
    "        if np.array_equal(np.array(self.current_pos), np.array(self.goal_pos)):\n",
    "            reward = 1.0\n",
    "            done = True\n",
    "        # elif self.move_count > self.num_rows * self.num_cols * 5:\n",
    "        #     reward = \n",
    "        #     done = True\n",
    "        else:\n",
    "            reward = -0.1/(self.num_rows * self.num_cols)\n",
    "            done = False\n",
    "\n",
    "        state_index = self._pos_to_index(self.current_pos)\n",
    "        self.move_count += 1\n",
    "        return state_index, reward, done, moved, {},\n",
    "\n",
    "    def _init_temp_walls(self):\n",
    "        for row in range(self.num_rows):\n",
    "            for col in range(self.num_cols):\n",
    "                if self.maze[row, col].endswith('$'):\n",
    "                    rand = random.randint(0, 1)\n",
    "                    if rand == 0:\n",
    "                        self.maze[row, col] = '.$'\n",
    "                    else:\n",
    "                        self.maze[row, col] = '#$'\n",
    "\n",
    "    def _is_valid_position(self, pos):\n",
    "        row, col = pos\n",
    "\n",
    "        if row < 0 or col < 0 or row >= self.num_rows or col >= self.num_cols:\n",
    "            return False\n",
    "        \n",
    "        if self.maze[row, col].startswith('#'):\n",
    "            return False\n",
    "\n",
    "        if self.maze[row, col].startswith('X'):\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def _translate_action(self, action):\n",
    "        if action == 0:\n",
    "            return (-1, 0) # Up\n",
    "        if action == 1:\n",
    "            return (1, 0) # Down\n",
    "        if action == 2:\n",
    "            return (0, -1) # Left\n",
    "        if action == 3:\n",
    "            return (0, 1) # Right\n",
    "        else:\n",
    "            return (0, 0)\n",
    "\n",
    "    def _is_valid_X_position(self, pos):\n",
    "        row, col, _ = pos\n",
    "\n",
    "        if row < 0 or col < 0 or row >= self.num_rows or col >= self.num_cols:\n",
    "            return False\n",
    "        \n",
    "        if row == self.current_pos[0] and col == self.current_pos[1]:\n",
    "            return False\n",
    "\n",
    "        if self.maze[row, col].startswith('#') or self.maze[row, col].startswith('X') or self.maze[row, col] == 'S' or self.maze[row, col] == 'G':\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def _update_Xes(self):\n",
    "        for X_pos in self.X_pos:\n",
    "            valid = False\n",
    "            new_X_pos = X_pos\n",
    "            counter = 0\n",
    "            while valid == False:\n",
    "                rand_move = 1\n",
    "                if X_pos[2].endswith('^'):\n",
    "                    rand_dir = random.randint(0, 1)\n",
    "                elif X_pos[2].endswith('>'):\n",
    "                    rand_dir = random.randint(2, 3)\n",
    "                else :\n",
    "                    rand_dir = random.randint(0, 3)\n",
    "\n",
    "                direction = self._translate_action(rand_dir)\n",
    "\n",
    "                new_X_pos = X_pos[0] + direction[0] * rand_move, X_pos[1] + direction[1] * rand_move, X_pos[2]\n",
    "                if self._is_valid_X_position(new_X_pos):\n",
    "                    valid = True\n",
    "                    self.maze[X_pos[0], X_pos[1]] = '.'\n",
    "                    self.maze[new_X_pos[0], new_X_pos[1]] = X_pos[2]\n",
    "\n",
    "                    self.X_pos.remove(X_pos)\n",
    "                    self.X_pos.append(new_X_pos)\n",
    "                else:\n",
    "                    counter += 1\n",
    "                    if counter > 5:\n",
    "                        break\n",
    "            \n",
    "            \n",
    "\n",
    "    def _pos_to_index(self, pos):\n",
    "        return pos[0] * self.num_cols + pos[1]\n",
    "    \n",
    "    def render(self):\n",
    "        \"\"\"\n",
    "            Render game environment using pygame by drawing elements for each cell by using nested loops. \n",
    "            You can simply print the maze grid as well, no necessary requirement for pygame\n",
    "        \"\"\"\n",
    "        self.screen.fill((255, 255, 255))\n",
    "\n",
    "        for row in range(self.num_rows):\n",
    "            for col in range(self.num_cols):\n",
    "                cell_left = col * self.cell_size\n",
    "                cell_top = row * self.cell_size\n",
    "\n",
    "                # try:\n",
    "                #     print(np.array(self.current_pos)==np.array([row,col]).reshape(-1,1))\n",
    "                # except Exception as e:\n",
    "                #     print('Initial state')\n",
    "\n",
    "                if self.maze[row, col].startswith('#'):\n",
    "                    pygame.draw.rect(self.screen, (0, 0, 0), (cell_left, cell_top, self.cell_size, self.cell_size))\n",
    "                elif self.maze[row, col] == 'S':\n",
    "                    pygame.draw.rect(self.screen, (0, 255, 0), (cell_left, cell_top, self.cell_size, self.cell_size))\n",
    "                elif self.maze[row, col] == 'G':\n",
    "                    pygame.draw.rect(self.screen, (255, 0, 0), (cell_left, cell_top, self.cell_size, self.cell_size))\n",
    "                elif self.maze[row, col].startswith('X'):\n",
    "                    pygame.draw.rect(self.screen, (125, 125, 125), (cell_left, cell_top, self.cell_size, self.cell_size))\n",
    "\n",
    "                if np.array_equal(np.array(self.current_pos), np.array([row, col])):  # Agent position\n",
    "                    pygame.draw.rect(self.screen, (0, 0, 255), (cell_left, cell_top, self.cell_size, self.cell_size))\n",
    "\n",
    "        pygame.display.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "gym.register(\n",
    "    id='MazeGame-v0',\n",
    "    entry_point=MazeGameEnv,\n",
    "    kwargs={'maze': None}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "def run(episodes, is_training=True, render=False):\n",
    "    \"\"\"\n",
    "    Run the maze problem\n",
    "\n",
    "    :param episodes: number of episodes to run\n",
    "    :param is_training: if True, the agent will learn, otherwise it will use a pre-trained model\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    maze = [\n",
    "        ['S', '$', '.',  'X>', '.',  '.',  '.',  '.'],\n",
    "        ['.', '#', '.',  '#',  'X^',  '#',  '.',  '.'],\n",
    "        ['.', '#', '.',  '#',  '.',  '#',  '#',  '$'],\n",
    "        ['.', '.', '.',  'X>',  '.',  '.',  '.',  '.'],\n",
    "        ['.', '.', '.',  '$',  '.',  '$',  'X^', '#'],\n",
    "        ['.', '$', 'X^', '$',  '.',  '$',  '.',  '.'],\n",
    "        ['.', '.', '.',  '.',  'X>',  '.', '.',  'G'],\n",
    "        ['$', '$', '$',  '$',  '$',  '$',  '$',  '#']\n",
    "    ]\n",
    "\n",
    "    env = gym.make('MazeGame-v0', maze=maze)\n",
    "\n",
    "    if(is_training):\n",
    "        q = np.zeros((len(maze) * len(maze[0]), 4))\n",
    "    else:\n",
    "        f = open('maze_game.pkl', 'rb')\n",
    "        q = pickle.load(f)\n",
    "        f.close()\n",
    "\n",
    "    learning_rate_a = 0.9\n",
    "    discount_factor_g = 0.9\n",
    "\n",
    "    epsilon = 1\n",
    "    epsilon_decay_rate = 0.0001\n",
    "    rng = np.random.default_rng()\n",
    "\n",
    "    rewards_per_episode = np.zeros(episodes)\n",
    "\n",
    "    for i in range(episodes):\n",
    "        state = env.reset()[0]\n",
    "        terminated = False\n",
    "        truncated = False\n",
    "        rewards = 0\n",
    "        not_moved_counter = 0\n",
    "        while (not terminated):\n",
    "\n",
    "            if render:\n",
    "                pygame.event.get()\n",
    "\n",
    "            if is_training and rng.random() < epsilon:\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action = np.argmax(q[state, :])\n",
    "           \n",
    "            if is_training:\n",
    "                new_state, reward, terminated, moved, _ = env.step(action)\n",
    "            else:\n",
    "                moved = False\n",
    "                temp = deepcopy(q)\n",
    "                while not moved:\n",
    "                    action = np.argmax(temp[state, :])\n",
    "                    new_state, reward, terminated, moved, _ = env.step(action)\n",
    "                    temp[state, action] = -np.inf\n",
    "                \n",
    "            if render:\n",
    "                env.render()\n",
    "                pygame.time.wait(200)\n",
    "\n",
    "            if is_training:\n",
    "                q[state, action] = q[state, action] + learning_rate_a * (\n",
    "                    reward + discount_factor_g * np.max(q[new_state, :]) - q[state, action]\n",
    "                )\n",
    "\n",
    "            state = new_state\n",
    "            rewards += reward\n",
    "\n",
    "        epsilon = max(epsilon - epsilon_decay_rate, 0)\n",
    "\n",
    "        if epsilon == 0:\n",
    "            learning_rate_a = 0.0001\n",
    "\n",
    "        rewards_per_episode[i] = rewards\n",
    "        if i % 100 == 0:\n",
    "            print(f'Episode {i+1}/{episodes}, rewards: {rewards}')\n",
    "\n",
    "    env.close()\n",
    "\n",
    "    if is_training:\n",
    "        f = open('maze_game.pkl','wb')\n",
    "        pickle.dump(q, f)\n",
    "        f.close()\n",
    "\n",
    "    mean_rewards = np.zeros(episodes)\n",
    "    for t in range(episodes):\n",
    "        mean_rewards[t] = np.mean(rewards_per_episode[max(0, t-100):(t+1)])\n",
    "    plt.plot(mean_rewards)\n",
    "    plt.savefig(f'maze_game_mean.png')\n",
    "\n",
    "    sum_rewards = np.zeros(episodes)\n",
    "    for t in range(episodes):\n",
    "        sum_rewards[t] = np.sum(rewards_per_episode[max(0, t-100):(t+1)])\n",
    "    plt.plot(sum_rewards)\n",
    "    plt.savefig(f'maze_game_sum.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piotrgasiorek/miniconda3/envs/IOWADC/lib/python3.12/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1/15000, rewards: -0.10781250000000386\n",
      "Episode 101/15000, rewards: -1.2968749999999365\n",
      "Episode 201/15000, rewards: 0.3812499999999954\n",
      "Episode 301/15000, rewards: 0.5515624999999978\n",
      "Episode 401/15000, rewards: 0.925\n",
      "Episode 501/15000, rewards: 0.7906250000000005\n",
      "Episode 601/15000, rewards: 0.909375\n",
      "Episode 701/15000, rewards: 0.7984375000000005\n",
      "Episode 801/15000, rewards: 0.4781249999999968\n",
      "Episode 901/15000, rewards: 0.8390625000000003\n",
      "Episode 1001/15000, rewards: 0.925\n",
      "Episode 1101/15000, rewards: 0.8890625000000001\n",
      "Episode 1201/15000, rewards: 0.9062500000000001\n",
      "Episode 1301/15000, rewards: 0.8109375000000004\n",
      "Episode 1401/15000, rewards: 0.8968750000000001\n",
      "Episode 1501/15000, rewards: 0.5249999999999975\n",
      "Episode 1601/15000, rewards: 0.909375\n",
      "Episode 1701/15000, rewards: 0.6734374999999996\n",
      "Episode 1801/15000, rewards: 0.8093750000000004\n",
      "Episode 1901/15000, rewards: 0.8171875000000004\n",
      "Episode 2001/15000, rewards: 0.5515624999999978\n",
      "Episode 2101/15000, rewards: 0.915625\n",
      "Episode 2201/15000, rewards: 0.8265625000000003\n",
      "Episode 2301/15000, rewards: 0.9187500000000001\n",
      "Episode 2401/15000, rewards: 0.8875000000000002\n",
      "Episode 2501/15000, rewards: 0.8671875000000002\n",
      "Episode 2601/15000, rewards: 0.5874999999999984\n",
      "Episode 2701/15000, rewards: 0.8359375000000003\n",
      "Episode 2801/15000, rewards: 0.8109375000000004\n",
      "Episode 2901/15000, rewards: 0.921875\n",
      "Episode 3001/15000, rewards: 0.8921875000000001\n",
      "Episode 3101/15000, rewards: 0.96875\n",
      "Episode 3201/15000, rewards: 0.9265625\n",
      "Episode 3301/15000, rewards: 0.9562499999999999\n",
      "Episode 3401/15000, rewards: 0.928125\n",
      "Episode 3501/15000, rewards: 0.9203125000000001\n",
      "Episode 3601/15000, rewards: 0.5078124999999972\n",
      "Episode 3701/15000, rewards: 0.8906250000000001\n",
      "Episode 3801/15000, rewards: 0.9125000000000001\n",
      "Episode 3901/15000, rewards: 0.971875\n",
      "Episode 4001/15000, rewards: 0.8906250000000001\n",
      "Episode 4101/15000, rewards: 0.6515624999999993\n",
      "Episode 4201/15000, rewards: 0.9046875000000001\n",
      "Episode 4301/15000, rewards: 0.959375\n",
      "Episode 4401/15000, rewards: 0.8828125000000002\n",
      "Episode 4501/15000, rewards: 0.909375\n",
      "Episode 4601/15000, rewards: 0.9515625\n",
      "Episode 4701/15000, rewards: 0.9484374999999999\n",
      "Episode 4801/15000, rewards: 0.93125\n",
      "Episode 4901/15000, rewards: 0.8859375000000002\n",
      "Episode 5001/15000, rewards: 0.953125\n",
      "Episode 5101/15000, rewards: 0.928125\n",
      "Episode 5201/15000, rewards: 0.9453125\n",
      "Episode 5301/15000, rewards: 0.9125000000000001\n",
      "Episode 5401/15000, rewards: 0.9265625\n",
      "Episode 5501/15000, rewards: 0.928125\n",
      "Episode 5601/15000, rewards: 0.9421875\n",
      "Episode 5701/15000, rewards: 0.8203125000000004\n",
      "Episode 5801/15000, rewards: 0.8984375000000001\n",
      "Episode 5901/15000, rewards: 0.9453125\n",
      "Episode 6001/15000, rewards: 0.9562499999999999\n",
      "Episode 6101/15000, rewards: 0.95\n",
      "Episode 6201/15000, rewards: 0.925\n",
      "Episode 6301/15000, rewards: 0.94375\n",
      "Episode 6401/15000, rewards: 0.9578125\n",
      "Episode 6501/15000, rewards: 0.9390624999999999\n",
      "Episode 6601/15000, rewards: 0.8015625000000004\n",
      "Episode 6701/15000, rewards: 0.9703125\n",
      "Episode 6801/15000, rewards: 0.965625\n",
      "Episode 6901/15000, rewards: 0.965625\n",
      "Episode 7001/15000, rewards: 0.9562499999999999\n",
      "Episode 7101/15000, rewards: 0.9546875\n",
      "Episode 7201/15000, rewards: 0.9328125\n",
      "Episode 7301/15000, rewards: 0.925\n",
      "Episode 7401/15000, rewards: 0.98125\n",
      "Episode 7501/15000, rewards: 0.94375\n",
      "Episode 7601/15000, rewards: 0.9000000000000001\n",
      "Episode 7701/15000, rewards: 0.9734375\n",
      "Episode 7801/15000, rewards: 0.9640625\n",
      "Episode 7901/15000, rewards: 0.928125\n",
      "Episode 8001/15000, rewards: 0.9265625\n",
      "Episode 8101/15000, rewards: 0.934375\n",
      "Episode 8201/15000, rewards: 0.925\n",
      "Episode 8301/15000, rewards: 0.93125\n",
      "Episode 8401/15000, rewards: 0.8812500000000002\n",
      "Episode 8501/15000, rewards: 0.925\n",
      "Episode 8601/15000, rewards: 0.9375\n",
      "Episode 8701/15000, rewards: 0.9359375\n",
      "Episode 8801/15000, rewards: 0.9671875\n",
      "Episode 8901/15000, rewards: 0.9796875\n",
      "Episode 9001/15000, rewards: 0.975\n",
      "Episode 9101/15000, rewards: 0.93125\n",
      "Episode 9201/15000, rewards: 0.9578125\n",
      "Episode 9301/15000, rewards: 0.9671875\n",
      "Episode 9401/15000, rewards: 0.965625\n",
      "Episode 9501/15000, rewards: 0.9734375\n",
      "Episode 9601/15000, rewards: 0.9703125\n",
      "Episode 9701/15000, rewards: 0.93125\n",
      "Episode 9801/15000, rewards: 0.9578125\n",
      "Episode 9901/15000, rewards: 0.9578125\n",
      "Episode 10001/15000, rewards: 0.978125\n",
      "Episode 10101/15000, rewards: 0.9734375\n",
      "Episode 10201/15000, rewards: 0.9765625\n",
      "Episode 10301/15000, rewards: 0.9640625\n",
      "Episode 10401/15000, rewards: 0.9734375\n",
      "Episode 10501/15000, rewards: 0.965625\n",
      "Episode 10601/15000, rewards: 0.971875\n",
      "Episode 10701/15000, rewards: 0.965625\n",
      "Episode 10801/15000, rewards: 0.978125\n",
      "Episode 10901/15000, rewards: 0.9609375\n",
      "Episode 11001/15000, rewards: 0.971875\n",
      "Episode 11101/15000, rewards: 0.9640625\n",
      "Episode 11201/15000, rewards: 0.971875\n",
      "Episode 11301/15000, rewards: 0.9640625\n",
      "Episode 11401/15000, rewards: 0.965625\n",
      "Episode 11501/15000, rewards: 0.96875\n",
      "Episode 11601/15000, rewards: 0.9671875\n",
      "Episode 11701/15000, rewards: 0.9765625\n",
      "Episode 11801/15000, rewards: 0.9703125\n",
      "Episode 11901/15000, rewards: 0.965625\n",
      "Episode 12001/15000, rewards: 0.96875\n",
      "Episode 12101/15000, rewards: 0.96875\n",
      "Episode 12201/15000, rewards: 0.9734375\n",
      "Episode 12301/15000, rewards: 0.965625\n",
      "Episode 12401/15000, rewards: 0.98125\n",
      "Episode 12501/15000, rewards: 0.9671875\n",
      "Episode 12601/15000, rewards: 0.9671875\n",
      "Episode 12701/15000, rewards: 0.971875\n",
      "Episode 12801/15000, rewards: 0.959375\n",
      "Episode 12901/15000, rewards: 0.9671875\n",
      "Episode 13001/15000, rewards: 0.98125\n",
      "Episode 13101/15000, rewards: 0.9796875\n",
      "Episode 13201/15000, rewards: 0.959375\n",
      "Episode 13301/15000, rewards: 0.9515625\n",
      "Episode 13401/15000, rewards: 0.9734375\n",
      "Episode 13501/15000, rewards: 0.9734375\n",
      "Episode 13601/15000, rewards: 0.9640625\n",
      "Episode 13701/15000, rewards: 0.9703125\n",
      "Episode 13801/15000, rewards: 0.9734375\n",
      "Episode 13901/15000, rewards: 0.9640625\n",
      "Episode 14001/15000, rewards: 0.971875\n",
      "Episode 14101/15000, rewards: 0.978125\n",
      "Episode 14201/15000, rewards: 0.98125\n",
      "Episode 14301/15000, rewards: 0.971875\n",
      "Episode 14401/15000, rewards: 0.9484374999999999\n",
      "Episode 14501/15000, rewards: 0.9609375\n",
      "Episode 14601/15000, rewards: 0.978125\n",
      "Episode 14701/15000, rewards: 0.975\n",
      "Episode 14801/15000, rewards: 0.98125\n",
      "Episode 14901/15000, rewards: 0.98125\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run(15000, is_training=True, render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piotrgasiorek/miniconda3/envs/IOWADC/lib/python3.12/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1/10, rewards: 0.9562499999999999\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_training\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Test the model\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 63\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(episodes, is_training, render)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m moved:\n\u001b[1;32m     62\u001b[0m         action \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(temp[state, :])\n\u001b[0;32m---> 63\u001b[0m         new_state, reward, terminated, moved, _ \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m         temp[state, action] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m render:\n",
      "File \u001b[0;32m~/miniconda3/envs/IOWADC/lib/python3.12/site-packages/gym/wrappers/order_enforcing.py:37\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/IOWADC/lib/python3.12/site-packages/gym/wrappers/env_checker.py:39\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 98\u001b[0m, in \u001b[0;36mMazeGameEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[1;32m     95\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m        Updates agentâ€™s position according to the action taken and provide reward\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_Xes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m        \n\u001b[1;32m     99\u001b[0m     moved \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     new_pos \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_pos)\n",
      "Cell \u001b[0;32mIn[2], line 180\u001b[0m, in \u001b[0;36mMazeGameEnv._update_Xes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m valid \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m     rand_move \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 180\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mX_pos\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendswith\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m^\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    181\u001b[0m         rand_dir \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m X_pos[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run(10, is_training=False, render=True) # Test the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IOwADC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
